{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеки:\n",
    "\n",
    "#!git clone https://github.com/KrisAnTis-Group/SigmaRental.git && pip install -r SigmaRental/requirements.txt",
    "#import sys; sys.path.append('/content/SigmaRental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# импорт библиотек\n",
    "import json\n",
    "import numpy as np\n",
    "from models.src import dataModifier as DM\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# открываем файл для прогнозирования целей по данным фичам\n",
    "dataJS = DM.json_load(\"data/test.json/test.json\")\n",
    "\n",
    "# выделим различные типы данные, выделяемые из предоставленных фич\n",
    "DigitTypes = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]\n",
    "FullTimeTypes = [\"created\"]\n",
    "TextTypes = [\"description\"]\n",
    "\n",
    "# итоговое решение ансамблируется из 5 моделей, получим прогнозы для каждой из моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# модель 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # состоит только из прямых числовых данных: количество ванных и спальных комнат,\n",
    "# долгота и широта, а также цена\n",
    "\n",
    "# парсим фичи из данных\n",
    "DigitData = np.array(DM.get_categories(dataJS, DigitTypes))\n",
    "\n",
    "m1_in = DigitData\n",
    "# выполняем нормализацию данных\n",
    "m1_in = DM.normalization(m1_in)\n",
    "# загружаем обученную модель 1 и делаем прогноз\n",
    "model1 = load_model('models/weights/model1.h5')\n",
    "preds_1 = model1.predict(m1_in)\n",
    "# добавляем прогноз в сумму общего решения\n",
    "preds = preds_1\n",
    "\n",
    "del model1\n",
    "del preds_1\n",
    "del m1_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# модель 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к числовым данным добавляется дата создания объявления\n",
    "# в данной модели было решено вычислить две фичи:\n",
    "# суммарная дата в днях\n",
    "# суммарное время в секундах\n",
    "\n",
    "FullTimeData = DM.get_categories(dataJS, FullTimeTypes)\n",
    "\n",
    "DataSum = DM.data_to_days(DM.fullData_to_data(FullTimeData))\n",
    "TimeSum = DM.time_to_sec(DM.fullData_to_time(FullTimeData))\n",
    "\n",
    "# объединяем фичи и нормализуем их\n",
    "m2_in = np.column_stack((DataSum, TimeSum))\n",
    "m2_in = np.asarray(m2_in).astype('float32')\n",
    "m2_in = DM.normalization(m2_in)\n",
    "m2_in = np.column_stack((DigitData, m2_in))\n",
    "\n",
    "model2 = load_model('models/weights/model2.h5')\n",
    "preds_2 = np.array(model2.predict(m2_in))\n",
    "# добавляем прогноз в общее решение\n",
    "preds += preds_2\n",
    "\n",
    "del model2\n",
    "del m2_in\n",
    "del preds_2\n",
    "del DataSum\n",
    "del TimeSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# модель 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# в данной модели дата представляется в виде набора фич вида\n",
    "# месяц, день, час, минута, секунда\n",
    "# год - игнорируется, т.к. он один и тот же для всего набора данных\n",
    "FullTimeData = DM.get_categories(dataJS, FullTimeTypes)\n",
    "\n",
    "DataMD = DM.data_to_MD(DM.fullData_to_data(FullTimeData))\n",
    "TimeHMS = DM.time_to_HMS(DM.fullData_to_time(FullTimeData))\n",
    "\n",
    "m3_in = np.column_stack((DataMD, TimeHMS))\n",
    "m3_in = np.asarray(m3_in).astype('float32')\n",
    "m3_in = DM.normalization(m3_in)\n",
    "m3_in = np.column_stack((DigitData, m3_in))\n",
    "\n",
    "model3 = load_model('models/weights/model3.h5')\n",
    "preds_3 = np.array(model3.predict(m3_in))\n",
    "\n",
    "preds += preds_3\n",
    "\n",
    "del model3\n",
    "del preds_3\n",
    "del DataMD\n",
    "del TimeHMS\n",
    "del DigitData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# модель 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данная модель состоит лишь из одной фичи - описания\n",
    "# текстовое представление данных выполняется самым простым прямым кодированием в бинарные разреженные вектора\n",
    "\n",
    "# получаем массив текстовых описаний\n",
    "TextData = DM.get_arr(dataJS, TextTypes)\n",
    "\n",
    "# определяем, что кодировка будет происходить по 3000 наиболее встречаемым слов\n",
    "tokinizer = Tokenizer(num_words=3000)\n",
    "# происходит процесс токенизации и последующим получением матрицы разреженных векторов\n",
    "tokinizer.fit_on_texts(TextData)\n",
    "sequences = tokinizer.texts_to_sequences(TextData)\n",
    "\n",
    "one_hot_results = tokinizer.texts_to_matrix(TextData, mode=\"binary\")\n",
    "TextData = np.array(one_hot_results)\n",
    "TextData = np.asarray(TextData).astype('int')\n",
    "\n",
    "model4 = load_model('models/weights/model4.h5')\n",
    "m4_in = TextData\n",
    "preds_4 = np.array(model4.predict(m4_in))\n",
    "\n",
    "preds += preds_4\n",
    "\n",
    "del model4\n",
    "del preds_4\n",
    "del TextData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# модель 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# модель включает в себя две группы входных данных:\n",
    "# все фичи, использованные в третьей моделе + текст\n",
    "# две группы входов вычисляются в сети отдельно, а затем конкатенируются в единый выход\n",
    "model5 = models.load_model('models/weights/model5.h5')\n",
    "m5_in = [m3_in, m4_in]\n",
    "preds_5 = np.array(model5.predict(m5_in))\n",
    "\n",
    "preds += preds_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ансамблируем итоговое решение\n",
    "final_preds = 0.2 * preds\n",
    "\n",
    "# берём из \"файла примера\" листинги объявлений\n",
    "listing_id = np.loadtxt(\"data/sample_submission.csv/sample_submission.csv\",\n",
    "                        skiprows=1,\n",
    "                        delimiter=\",\")\n",
    "\n",
    "# технические детали оформления выходного файла\n",
    "listing = []\n",
    "for q in listing_id[:, :1]:\n",
    "    listing.append(q[0])\n",
    "\n",
    "listing_id = np.array(listing)\n",
    "listing_id = np.asarray(listing_id).astype('int')\n",
    "\n",
    "final_preds = np.asarray(final_preds).astype('float32')\n",
    "\n",
    "final_preds = np.column_stack(\n",
    "    (final_preds[:, 2], final_preds[:, 1], final_preds[:, 0]))\n",
    "\n",
    "# сохраняем вычесленные вероятности с заданным форматом\n",
    "np.savetxt('out.csv',\n",
    "           np.column_stack((listing_id, final_preds)),\n",
    "           fmt='%2d,%1.17f,%1.17f,%1.17f',\n",
    "           delimiter=',')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
